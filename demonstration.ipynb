{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CiRA Demonstration\n",
    "\n",
    "This notebook demonstrates the usage of the CiRA pipeline. Be sure to fulfill all prerequisites as specified in the [readme](README.md), especially the availability of the two pretrained models, both of which are [available for download on Zenodo](https://doi.org/10.5281/zenodo.7186287). If you run the code from the provided container, the models are already included."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate the Models\n",
    "\n",
    "The location of the two pre-trained models must be available to the CiRA converter. You can hardcode the location of the pre-trained models to the two variables `model_classification` and `model_labeling`, or use the subsequent snippet, in which the location of the models is determined. If you run the code locally, \n",
    "\n",
    "1. create a `.env` file and \n",
    "2. define the variables `MODEL_CLASSIFICATION` and `MODEL_LABELING` with the respective URLs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification model path: ./model/cira-classifier.bin\n",
      "Labeling model path: ./model/cira-labeler.ckpt\n"
     ]
    }
   ],
   "source": [
    "import model_locator\n",
    "\n",
    "model_classification = model_locator.classification()\n",
    "model_labeling = model_locator.labeling()\n",
    "\n",
    "print(f'Classification model path: {model_classification}')\n",
    "print(f'Labeling model path: {model_labeling}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Converter\n",
    "\n",
    "Instantiate the CiRA converter which is realized in [src.cira.CiRAConverter](./src/cira.py). The instantiation of the converter will output some warning messages, which can be safely ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juf\\Workspace\\BTH\\NLP_RE\\cira\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from src.cira import CiRAConverter\n",
    "cira = CiRAConverter(classifier_causal_model_path=model_classification, converter_s2l_model_path=model_labeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the converter\n",
    "\n",
    "Finally, apply the converter to utilize the CiRA pipeline. This usually includes four steps:\n",
    "\n",
    "1. Define a single natural language sentence. CiRA is currently only trained on grammatically correct, full sentences.\n",
    "2. Classify the sentence to determine, whether the sentence is causal or nor.\n",
    "3. If the sentence is causal, process it to generate labels, convert it into a cause-effect-graph, and finally derive a minimal set of test cases covering the requirement.\n",
    "\n",
    "Non-causal sentences cannot be processed by the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence: str = \"Upon deploying the system a log has to be created.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CiRA classified the sentence \"Upon deploying the system a log has to be created.\" to be *causal* with a confidence of 99.80%.\n"
     ]
    }
   ],
   "source": [
    "causal, confidence = cira.classify(sentence)\n",
    "print(f'CiRA classified the sentence \"{sentence}\" to be {\"*\" if causal else \"*non\"}causal* with a confidence of {confidence:.2%}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels associated to the sentence: [[5> (L0) Cause1  (None L1): [15> (L2) Variable <25] [5> (L4) Condition <14] <25], [26> (L1) Effect1 : [26> (L3) Variable <31] [32> (L5) Condition <49] <49], [15> (L2) Variable <25], [26> (L3) Variable <31], [5> (L4) Condition <14], [32> (L5) Condition <49]]\n",
      "\n",
      "Converted cause-effect-graph: [the system].(deploying) ===> [a log].(has to be created)\n",
      "\n",
      "Minimal test suite: \n",
      "  id  | the system     | a log\n",
      "----  ---------------  -----------------------\n",
      "   1  | deploying      | has to be created\n",
      "   2  | not deploying  | not has to be created\n"
     ]
    }
   ],
   "source": [
    "if causal:\n",
    "    labels, graph, suite = cira.process(sentence)\n",
    "\n",
    "    print(f'Labels associated to the sentence: {labels}\\n')\n",
    "    print(f'Converted cause-effect-graph: {graph}\\n')\n",
    "    print(f'Minimal test suite: \\n{suite}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cira",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "771fad8496487585f7e7466d75eb439d465b4bb255d9580a2671fb906c27f82d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
