{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CiRA Demonstration\n",
    "\n",
    "This notebook demonstrates the usage of the CiRA pipeline. Be sure to fulfill all prerequisites as specified in the [readme](README.md), especially the availability of the two pretrained models, both of which are [available for download on Zenodo](https://doi.org/10.5281/zenodo.7186287). If you run the code from the provided container, the models are already included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate the Models\n",
    "\n",
    "The location of the two pre-trained models must be available to the CiRA converter. You can hardcode the location of the pre-trained models to the two variables `model_classification` and `model_labeling`, or use the subsequent snippet, in which the location of the models is determined. If you run the code locally, \n",
    "\n",
    "1. create a `.env` file and \n",
    "2. define the variables `MODEL_CLASSIFICATION` and `MODEL_LABELING` with the respective URLs. \n",
    "\n",
    "If you run the code from the container, then the suffix `_DEV` in the environment variables will distinguish the location of the models locally from those in the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "model_env_suffix = '_DEV' if ('DEV_CONTAINER' in os.environ) else ''\n",
    "\n",
    "model_classification = os.environ[f'MODEL_CLASSIFICATION{model_env_suffix}']\n",
    "model_labeling = os.environ[f'MODEL_LABELING{model_env_suffix}']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Converter\n",
    "\n",
    "Instantiate the CiRA converter which is realized in [src.cira.CiRAConverter](./src/cira.py). The instantiation of the converter will output some warning messages, which can be safely ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juf\\Workspace\\BTH\\NLP_RE\\cira\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from src.cira import CiRAConverter\n",
    "cira = CiRAConverter(classifier_causal_model_path=model_classification, converter_s2l_model_path=model_labeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the converter\n",
    "\n",
    "Finally, apply the converter to utilize the CiRA pipeline. This usually includes four steps:\n",
    "\n",
    "1. Define a single natural language sentence. CiRA is currently only trained on grammatically correct, full sentences.\n",
    "2. Classify the sentence to determine, whether the sentence is causal or nor.\n",
    "3. If the sentence is causal, process it to generate labels, convert it into a cause-effect-graph, and finally derive a minimal set of test cases covering the requirement.\n",
    "\n",
    "Non-causal sentences cannot be processed by the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence: str = \"If the red button is pressed and background operations are not running then the system shuts down.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CiRA classified the sentence \"If the red button is pressed and background operations are not running then the system shuts down.\" to be *causal* with a confidence of 97.73%.\n"
     ]
    }
   ],
   "source": [
    "causal, confidence = cira.classify(sentence)\n",
    "print(f'CiRA classified the sentence \"{sentence}\" to be {\"*\" if causal else \"*non\"}causal* with a confidence of {confidence:.2%}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels associated to the sentence: [[3> (L0) Cause1  (AND L1): [3> (L4) Variable <17] [18> (L7) Condition <28] <28], [33> (L1) Cause2  (None L2): [33> (L5) Variable <54] [63> (L8) Condition <70] [55> (L10) Negation <62] <70], [76> (L2) Effect1 : [76> (L6) Variable <86] [87> (L9) Condition <97] <97], [29> (L3) Conjunction <32], [3> (L4) Variable <17], [33> (L5) Variable <54], [76> (L6) Variable <86], [18> (L7) Condition <28], [63> (L8) Condition <70], [87> (L9) Condition <97], [55> (L10) Negation <62]]\n",
      "\n",
      "Converted cause-effect-graph: ([the red button].(is pressed) && NOT [background operations].(running)) ===> [the system].(shuts down)\n",
      "\n",
      "Minimal test suite: \n",
      "  id  | the red button    background operations    | the system\n",
      "----  ------------------  -----------------------  ----------------\n",
      "   1  | is pressed        not running              | shuts down\n",
      "   2  | not is pressed    not running              | not shuts down\n",
      "   3  | is pressed        running                  | not shuts down\n"
     ]
    }
   ],
   "source": [
    "if causal:\n",
    "    labels, graph, suite = cira.process(sentence)\n",
    "\n",
    "    print(f'Labels associated to the sentence: {labels}\\n')\n",
    "    print(f'Converted cause-effect-graph: {graph}\\n')\n",
    "    print(f'Minimal test suite: \\n{suite}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99184904623d560141b8ef29ab0847add0f2bbbf43eef3ab8f35c2baaad57bc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
